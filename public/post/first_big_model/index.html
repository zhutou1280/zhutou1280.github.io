<!DOCTYPE html>
<html
  itemscope
  itemtype="http://schema.org/WebPage"
  lang="en"
  class="color-toggle-hidden"
  
>
  <head>
    <meta charset="UTF-8" />
<meta name="referrer" content="no-referrer" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="generator" content="Hugo 0.135.0">
  <meta name="robots" content="index, follow" />
  <meta name="description" content="[TOC]
一、大模型简介 1.1 什么是大模型 大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。 LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。 大模型实际上是个语言模型，用来处理复杂的语言任务，如文本生成、语言翻译、问题回答等。
1.2 为什么叫大模型 大模型也是属于机器学习的一种，是深度学习的思想融入语言模型中的强大神经网络模型。 模型通俗的理解，就是数学模型，用公式来说就是y=fn(x1,x2) 大模型主要体现在这个大字。大的概念是一个参数多，能达到上亿个参数。对应公式中可能存在上亿个参数。另一个是数据量大，用于训练的数据可以达到PB级别。再者就是计算资源密集，训练和推理需要大量的计算资源。
二、检索增强生成RAG简介 2.1 什么是RAG 大模型不是万能的，在某些情况下，无法提供准确的答案。为了提高模型的性能和输出质量，产生了一种新的模型架构方式：检索增强生成（RAG, Retrieval-Augmented Generation）" />

    <title>开发一个本地大模型应用 | Wild Bill Blog</title>

    <link rel="icon" type="image/svg+xml" href="/favicon/favicon.svg" />
<link
  rel="icon"
  type="image/png"
  sizes="32x32"
  href="/favicon/favicon-32x32.png"
/>
<link
  rel="icon"
  type="image/png"
  sizes="16x16"
  href="/favicon/favicon-16x16.png"
/>

    

    
  <meta
    property="og:title"
    content="开发一个本地大模型应用"
  />
  <meta property="og:site_name" content="Wild Bill Blog" />
  <meta property="og:description" content="[TOC]
一、大模型简介 1.1 什么是大模型 大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。 LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。 大模型实际上是个语言模型，用来处理复杂的语言任务，如文本生成、语言翻译、问题回答等。
1.2 为什么叫大模型 大模型也是属于机器学习的一种，是深度学习的思想融入语言模型中的强大神经网络模型。 模型通俗的理解，就是数学模型，用公式来说就是y=fn(x1,x2) 大模型主要体现在这个大字。大的概念是一个参数多，能达到上亿个参数。对应公式中可能存在上亿个参数。另一个是数据量大，用于训练的数据可以达到PB级别。再者就是计算资源密集，训练和推理需要大量的计算资源。
二、检索增强生成RAG简介 2.1 什么是RAG 大模型不是万能的，在某些情况下，无法提供准确的答案。为了提高模型的性能和输出质量，产生了一种新的模型架构方式：检索增强生成（RAG, Retrieval-Augmented Generation）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.org/post/first_big_model/" />

<meta property="article:section" content="Post" />
    <meta
      property="article:published_time"
      content="2024-10-09T14:45:23+08:00"
    />
    <meta
      property="article:modified_time"
      content="2024-10-09T14:45:23+08:00"
    />


  <meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="开发一个本地大模型应用" />
  <meta name="twitter:description" content="[TOC]
一、大模型简介 1.1 什么是大模型 大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。 LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。 大模型实际上是个语言模型，用来处理复杂的语言任务，如文本生成、语言翻译、问题回答等。
1.2 为什么叫大模型 大模型也是属于机器学习的一种，是深度学习的思想融入语言模型中的强大神经网络模型。 模型通俗的理解，就是数学模型，用公式来说就是y=fn(x1,x2) 大模型主要体现在这个大字。大的概念是一个参数多，能达到上亿个参数。对应公式中可能存在上亿个参数。另一个是数据量大，用于训练的数据可以达到PB级别。再者就是计算资源密集，训练和推理需要大量的计算资源。
二、检索增强生成RAG简介 2.1 什么是RAG 大模型不是万能的，在某些情况下，无法提供准确的答案。为了提高模型的性能和输出质量，产生了一种新的模型架构方式：检索增强生成（RAG, Retrieval-Augmented Generation）" />

<script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "BlogPosting",
      "articleSection": "Post",
      "name": "开发一个本地大模型应用",
      "url" : "https://example.org/post/first_big_model/",
      "headline": "开发一个本地大模型应用",
      "description": "[TOC]\n一、大模型简介 1.1 什么是大模型 大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。 LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。 大模型实际上是个语言模型，用来处理复杂的语言任务，如文本生成、语言翻译、问题回答等。\n1.2 为什么叫大模型 大模型也是属于机器学习的一种，是深度学习的思想融入语言模型中的强大神经网络模型。 模型通俗的理解，就是数学模型，用公式来说就是y=fn(x1,x2) 大模型主要体现在这个大字。大的概念是一个参数多，能达到上亿个参数。对应公式中可能存在上亿个参数。另一个是数据量大，用于训练的数据可以达到PB级别。再者就是计算资源密集，训练和推理需要大量的计算资源。\n二、检索增强生成RAG简介 2.1 什么是RAG 大模型不是万能的，在某些情况下，无法提供准确的答案。为了提高模型的性能和输出质量，产生了一种新的模型架构方式：检索增强生成（RAG, Retrieval-Augmented Generation）",
      "wordCount" : "530",
      "inLanguage": "en",
      "isFamilyFriendly": "true",
      "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://example.org/post/first_big_model/"
      },
      "author" : [
      ],
      "copyrightHolder" : "Wild Bill Blog",
      "copyrightYear" : "2024",
      "dateCreated": "2024-10-09T14:45:23.00Z",
      "datePublished": "2024-10-09T14:45:23.00Z",
      "dateModified": "2024-10-09T14:45:23.00Z",
      "publisher":{
          "@type":"Organization",
          "name": "Wild Bill Blog",
          "url": "https://example.org/",
          "logo": {
              "@type": "ImageObject",
              "url": "https://example.org/brand.svg",
              "width":"32",
              "height":"32"
          }
      }
  }
  </script>


    
  <script src="/js/colortheme-84f7e8e5.bundle.min.js"></script>
<script src="/js/main-335bae8d.bundle.min.js"></script>

<link
  rel="preload"
  as="font"
  href="/fonts/Metropolis.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  href="/fonts/LiberationSans.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  href="/fonts/GeekblogIcons.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>

<link
  rel="preload"
  href="/main-d8f6de16.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/main-d8f6de16.min.css"
  media="all"
/>

<link
  rel="preload"
  href="/mobile-7fcdde51.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/mobile-7fcdde51.min.css"
  media="screen and (max-width: 45rem)"
/>

<link
  rel="preload"
  href="/print-cc34f864.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/print-cc34f864.min.css"
  media="print"
/>

<link
  rel="preload"
  href="/custom.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/custom.css"
  media="all"
/>
  <link href="https://example.org/post/first_big_model/" rel="canonical" type="text/html" />
    <link href="https://example.org/index.xml" rel="alternate" type="application/rss+xml" title="Wild Bill Blog rss Feed" />

<!-- Made with Geekblog theme https://github.com/thegeeklab/hugo-geekblog -->

    

  </head>

  <body>
    
  <!-- geekblog include: /sprites/geekblog.svg -->
  <svg class="svg-sprite" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_back" xmlns="http://www.w3.org/2000/svg"><path d="M31.999 14.035v3.93H7.673l11.134 11.228L16 32 .001 16.001 16 .002l2.807 2.807L7.673 14.037h24.326z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_left" xmlns="http://www.w3.org/2000/svg"><path d="M7.954 17.965v5.988L.001 16l7.953-7.953v5.988H32v3.93H7.954z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_right" xmlns="http://www.w3.org/2000/svg"><path d="M24.046 14.035V8.047L31.999 16l-7.953 7.953v-5.988H0v-3.93h24.046z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_bitbucket" xmlns="http://www.w3.org/2000/svg"><path d="M15.905 13.355c.189 1.444-1.564 2.578-2.784 1.839-1.375-.602-1.375-2.784-.034-3.403 1.151-.705 2.818.223 2.818 1.564zm1.907-.361c-.309-2.44-3.076-4.056-5.328-3.042-1.426.636-2.389 2.148-2.32 3.747.086 2.097 2.08 3.815 4.176 3.626s3.729-2.234 3.472-4.331zm4.108-9.315c-.756-.997-2.045-1.169-3.179-1.358-3.214-.516-6.513-.533-9.727.034-1.066.172-2.269.361-2.939 1.323 1.1 1.031 2.664 1.186 4.073 1.358 2.544.327 5.156.344 7.699.017 1.426-.172 3.008-.309 4.073-1.375zm.979 17.788c-.481 1.684-.206 3.953-1.994 4.932-3.076 1.701-6.806 1.89-10.191 1.289-1.787-.327-3.884-.894-4.864-2.578-.43-1.65-.705-3.334-.98-5.018l.103-.275.309-.155c5.121 3.386 12.288 3.386 17.427 0 .808.241.206 1.22.189 1.805zM26.01 4.951c-.584 3.764-1.255 7.51-1.908 11.257-.189 1.1-1.255 1.719-2.148 2.183-3.214 1.615-6.96 1.89-10.483 1.512-2.389-.258-4.829-.894-6.771-2.389-.911-.705-.911-1.908-1.083-2.922-.602-3.523-1.289-7.046-1.719-10.604.206-1.547 1.942-2.217 3.231-2.698C6.848.654 8.686.362 10.508.19c3.884-.378 7.854-.241 11.618.859 1.341.395 2.784.945 3.695 2.097.412.533.275 1.203.189 1.805z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_bookmark" xmlns="http://www.w3.org/2000/svg"><path d="M20.357 5.856q1.157 0 2.043.851t.885 2.008v23.284l-10.212-4.357-10.144 4.357V8.715q0-1.157.885-2.008t2.042-.851h14.502zm5.787 18.859V5.856q0-1.157-.851-2.042t-2.008-.885H8.715q0-1.157.885-2.042t2.043-.885h14.502q1.157 0 2.043.885t.885 2.042v23.216z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_auto" xmlns="http://www.w3.org/2000/svg"><path d="M16.846 18.938h2.382L15.22 7.785h-2.44L8.772 18.938h2.382l.871-2.44h3.95zm7.087-9.062L27.999 14l-4.066 4.124v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809zm-11.385 4.937L14 10.282l1.452 4.531h-2.904z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_dark" xmlns="http://www.w3.org/2000/svg"><path d="M14 21.435q3.079 0 5.257-2.178T21.435 14t-2.178-5.257T14 6.565q-1.51 0-3.079.697 1.917.871 3.108 2.701T15.22 14t-1.191 4.037-3.108 2.701q1.568.697 3.079.697zm9.933-11.559L27.999 14l-4.066 4.124v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_light" xmlns="http://www.w3.org/2000/svg"><path d="M14 21.435q3.079 0 5.257-2.178T21.435 14t-2.178-5.257T14 6.565 8.743 8.743 6.565 14t2.178 5.257T14 21.435zm9.933-3.311v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809L27.999 14z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_check" xmlns="http://www.w3.org/2000/svg"><path d="M8.885 20.197 25.759 3.323l2.24 2.24L8.885 24.677 0 15.792l2.24-2.24z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_check_circle_outline" xmlns="http://www.w3.org/2000/svg"><path d="M14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm6.441 7.822 1.972 1.972-11.239 11.239L4.207 14l1.972-1.972 4.995 4.995z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_clear" xmlns="http://www.w3.org/2000/svg"><path d="M32 3.222 19.222 16 32 28.778l-3.221 3.221-12.778-12.778L3.223 31.999.002 28.778 12.78 16 .002 3.222 3.223.001l12.778 12.778L28.779.001z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_cloud_off" xmlns="http://www.w3.org/2000/svg"><path d="M9.023 10.5H7q-1.914 0-3.281 1.395t-1.367 3.309 1.367 3.281T7 19.852h11.375zM3.5 4.976l1.477-1.477L24.5 23.022l-1.477 1.477-2.352-2.297H6.999q-2.898 0-4.949-2.051t-2.051-4.949q0-2.844 1.969-4.867t4.758-2.133zm19.086 5.578q2.242.164 3.828 1.832T28 16.351q0 3.008-2.461 4.758l-1.695-1.695q1.805-.984 1.805-3.063 0-1.422-1.039-2.461t-2.461-1.039h-1.75v-.602q0-2.68-1.859-4.539t-4.539-1.859q-1.531 0-2.953.711l-1.75-1.695Q11.431 3.5 14.001 3.5q2.953 0 5.496 2.078t3.09 4.977z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_code" xmlns="http://www.w3.org/2000/svg"><path d="M9.917 24.5a1.75 1.75 0 1 0-3.501.001 1.75 1.75 0 0 0 3.501-.001zm0-21a1.75 1.75 0 1 0-3.501.001A1.75 1.75 0 0 0 9.917 3.5zm11.666 2.333a1.75 1.75 0 1 0-3.501.001 1.75 1.75 0 0 0 3.501-.001zm1.75 0a3.502 3.502 0 0 1-1.75 3.026c-.055 6.581-4.721 8.039-7.82 9.023-2.898.911-3.846 1.349-3.846 3.117v.474a3.502 3.502 0 0 1 1.75 3.026c0 1.932-1.568 3.5-3.5 3.5s-3.5-1.568-3.5-3.5c0-1.294.711-2.424 1.75-3.026V6.526A3.502 3.502 0 0 1 4.667 3.5c0-1.932 1.568-3.5 3.5-3.5s3.5 1.568 3.5 3.5a3.502 3.502 0 0 1-1.75 3.026v9.06c.93-.456 1.914-.766 2.807-1.039 3.391-1.075 5.323-1.878 5.359-5.687a3.502 3.502 0 0 1-1.75-3.026c0-1.932 1.568-3.5 3.5-3.5s3.5 1.568 3.5 3.5z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_contacts" xmlns="http://www.w3.org/2000/svg"><path d="M22.688 22.688v-2q0-1.5-2.281-2.438t-4.406-.938-4.406.938-2.281 2.438v2h13.375zM16 9q-1.25 0-2.125.875T13 12t.875 2.125T16 15t2.125-.875T19 12t-.875-2.125T16 9zm10.688-3.687q1.063 0 1.844.813t.781 1.875v16q0 1.063-.781 1.875t-1.844.813H5.313q-1.063 0-1.844-.813t-.781-1.875v-16q0-1.063.781-1.875t1.844-.813h21.375zM5.313 32v-2.688h21.375V32H5.313zM26.688 0v2.688H5.313V0h21.375z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_copy" xmlns="http://www.w3.org/2000/svg"><path d="M23.502 25.438V7.626H9.562v17.812h13.94zm0-20.315q1.013 0 1.787.745t.774 1.757v17.812q0 1.013-.774 1.787t-1.787.774H9.562q-1.013 0-1.787-.774t-.774-1.787V7.625q0-1.013.774-1.757t1.787-.745h13.94zM19.689 0v2.562H4.438v17.812H1.936V2.562q0-1.013.745-1.787T4.438.001h15.251z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_create" xmlns="http://www.w3.org/2000/svg"><path d="m31.499 7.167-3.25 3.25-6.666-6.666 3.25-3.25q.5-.5 1.25-.5t1.25.5l4.166 4.166q.5.5.5 1.25t-.5 1.25zM.001 25.333 19.667 5.667l6.666 6.666L6.667 31.999H.001v-6.666z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_dangerous" xmlns="http://www.w3.org/2000/svg"><path d="M21.802 19.833 15.969 14l5.833-5.833-1.969-1.969L14 12.031 8.167 6.198 6.198 8.167 12.031 14l-5.833 5.833 1.969 1.969L14 15.969l5.833 5.833zM19.833 0 28 8.167v11.666L19.833 28H8.167L0 19.833V8.167L8.167 0h11.666z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_date" xmlns="http://www.w3.org/2000/svg"><path d="M27.192 28.844V11.192H4.808v17.652h22.384zm0-25.689q1.277 0 2.253.976t.976 2.253v22.459q0 1.277-.976 2.216t-2.253.939H4.808q-1.352 0-2.291-.901t-.939-2.253V6.385q0-1.277.939-2.253t2.291-.976h1.577V.001h3.23v3.155h12.769V.001h3.23v3.155h1.577zm-3.155 11.267v3.155h-3.23v-3.155h3.23zm-6.46 0v3.155h-3.155v-3.155h3.155zm-6.384 0v3.155h-3.23v-3.155h3.23z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_download" xmlns="http://www.w3.org/2000/svg"><path d="M2.866 28.209h26.269v3.79H2.866v-3.79zm26.268-16.925L16 24.418 2.866 11.284h7.493V.001h11.283v11.283h7.493z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_email" xmlns="http://www.w3.org/2000/svg"><path d="M28.845 9.615v-3.23L16 14.422 3.155 6.385v3.23L16 17.577zm0-6.46q1.277 0 2.216.977T32 6.385v19.23q0 1.277-.939 2.253t-2.216.977H3.155q-1.277 0-2.216-.977T0 25.615V6.385q0-1.277.939-2.253t2.216-.977h25.69z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_error_outline" xmlns="http://www.w3.org/2000/svg"><path d="M14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm-1.38 6.967h2.761v8.413H12.62V6.967zm0 11.239h2.761v2.826H12.62v-2.826z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_fire" xmlns="http://www.w3.org/2000/svg"><path d="M17.689 21.998q-.32.32-.8.576t-.864.384q-1.152.384-2.272.032t-1.888-.992q-.128-.128-.096-.256t.16-.192q1.216-.384 1.92-1.216t.96-1.792q.192-.896-.064-1.728t-.384-1.728q-.128-.704-.096-1.376t.288-1.312q0-.128.128-.128t.192.064q.384.832.992 1.472t1.28 1.216 1.216 1.248.672 1.568q.064.384.064.704.064.96-.32 1.92t-1.088 1.536zm3.84-10.944q-.768-.704-1.6-1.28t-1.6-1.344q-1.536-1.536-2.016-3.584t.16-4.16q.128-.32-.096-.544t-.544-.096q-.768.32-1.44.768t-1.312.896q-1.984 1.664-3.136 3.936T8.633 10.51t.8 5.088q0 .128.032.256t.032.256q0 .576-.512.832t-1.024-.192q-.128-.192-.192-.32-1.024-1.28-1.376-2.912t-.096-3.232q.064-.384-.288-.576t-.608.128q-1.28 1.664-1.856 3.68t-.448 4.064q0 .576.096 1.184t.288 1.184q.448 1.536 1.216 2.816 1.216 2.048 3.264 3.424t4.416 1.696q2.496.32 5.024-.256t4.448-2.304q1.408-1.344 2.208-3.104t.864-3.68-.704-3.712q-.064-.128-.096-.224t-.096-.224q-.576-1.088-1.28-1.984-.256-.384-.544-.704t-.672-.64z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_git" xmlns="http://www.w3.org/2000/svg"><path d="M27.472 12.753 15.247.529a1.803 1.803 0 0 0-2.55 0l-2.84 2.84 2.137 2.137a2.625 2.625 0 0 1 3.501 3.501l3.499 3.499a2.625 2.625 0 1 1-1.237 1.237l-3.499-3.499c-.083.04-.169.075-.257.106v7.3a2.626 2.626 0 1 1-1.75 0v-7.3a2.626 2.626 0 0 1-1.494-3.607L8.62 4.606l-8.09 8.09a1.805 1.805 0 0 0 0 2.551l12.225 12.224a1.803 1.803 0 0 0 2.55 0l12.168-12.168a1.805 1.805 0 0 0 0-2.551z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_gitea" xmlns="http://www.w3.org/2000/svg"><path d="M5.581 7.229c-2.46-.005-5.755 1.559-5.573 5.48.284 6.125 6.56 6.693 9.068 6.743.275 1.149 3.227 5.112 5.412 5.32h9.573c5.741-.381 10.04-17.363 6.853-17.427-5.271.248-8.395.373-11.073.395v5.3l-.835-.369-.005-4.928c-3.075-.001-5.781-.144-10.919-.397-.643-.004-1.539-.113-2.501-.116zm.348 2.166h.293c.349 3.14.917 4.976 2.067 7.781-2.933-.347-5.429-1.199-5.888-4.38-.237-1.647.563-3.365 3.528-3.401zm11.409 3.087c.2.003.404.04.596.128l.999.431-.716 1.305h-.007a.996.996 0 0 0-.321.053l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006a.767.767 0 0 0 .151.233l-.001-.001-1.235 2.248a.99.99 0 0 0-.302.052l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006c.128.31.457.527.843.527a.987.987 0 0 0 .31-.049l-.006.002c.348-.114.592-.406.592-.749 0-.097-.02-.19-.056-.277l.002.006a.784.784 0 0 0-.211-.293l1.203-2.189a.999.999 0 0 0 .397-.041l-.006.002a.942.942 0 0 0 .285-.15l-.001.001c.464.195.844.353 1.117.488.411.203.556.337.6.487.044.147-.004.429-.236.925-.173.369-.46.893-.799 1.511h-.02a.991.991 0 0 0-.321.053l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006c.128.31.457.527.843.527a.987.987 0 0 0 .31-.049l-.006.002c.348-.114.592-.406.592-.749a.703.703 0 0 0-.055-.275l.002.006a.802.802 0 0 0-.183-.27l.001.001c.335-.611.623-1.136.808-1.531.251-.536.381-.935.267-1.32s-.467-.636-.933-.867c-.307-.151-.689-.311-1.147-.503a.723.723 0 0 0-.052-.324l.002.006a.792.792 0 0 0-.194-.279l.704-1.284 3.899 1.684c.704.305.995 1.053.653 1.68l-2.68 4.907c-.343.625-1.184.884-1.888.58l-5.516-2.384c-.704-.304-.996-1.053-.653-1.68l2.68-4.905c.235-.431.707-.687 1.207-.707z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_github" xmlns="http://www.w3.org/2000/svg"><path d="M16 .394c8.833 0 15.999 7.166 15.999 15.999 0 7.062-4.583 13.062-10.937 15.187-.813.146-1.104-.354-1.104-.771 0-.521.021-2.25.021-4.396 0-1.5-.5-2.458-1.083-2.958 3.562-.396 7.312-1.75 7.312-7.896 0-1.75-.625-3.167-1.646-4.291.167-.417.708-2.042-.167-4.25-1.333-.417-4.396 1.646-4.396 1.646a15.032 15.032 0 0 0-8 0S8.937 6.602 7.603 7.018c-.875 2.208-.333 3.833-.167 4.25-1.021 1.125-1.646 2.542-1.646 4.291 0 6.125 3.729 7.5 7.291 7.896-.458.417-.875 1.125-1.021 2.146-.917.417-3.25 1.125-4.646-1.333-.875-1.521-2.458-1.646-2.458-1.646-1.562-.021-.104.979-.104.979 1.042.479 1.771 2.333 1.771 2.333.938 2.854 5.396 1.896 5.396 1.896 0 1.333.021 2.583.021 2.979 0 .417-.292.917-1.104.771C4.582 29.455-.001 23.455-.001 16.393-.001 7.56 7.165.394 15.998.394zM6.063 23.372c.042-.083-.021-.187-.146-.25-.125-.042-.229-.021-.271.042-.042.083.021.187.146.25.104.062.229.042.271-.042zm.646.709c.083-.062.062-.208-.042-.333-.104-.104-.25-.146-.333-.062-.083.062-.062.208.042.333.104.104.25.146.333.062zm.625.937c.104-.083.104-.25 0-.396-.083-.146-.25-.208-.354-.125-.104.062-.104.229 0 .375s.271.208.354.146zm.875.875c.083-.083.042-.271-.083-.396-.146-.146-.333-.167-.417-.062-.104.083-.062.271.083.396.146.146.333.167.417.062zm1.187.521c.042-.125-.083-.271-.271-.333-.167-.042-.354.021-.396.146s.083.271.271.312c.167.062.354 0 .396-.125zm1.313.104c0-.146-.167-.25-.354-.229-.187 0-.333.104-.333.229 0 .146.146.25.354.229.187 0 .333-.104.333-.229zm1.208-.208c-.021-.125-.187-.208-.375-.187-.187.042-.312.167-.292.312.021.125.187.208.375.167s.312-.167.292-.292z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_gitlab" xmlns="http://www.w3.org/2000/svg"><path d="M1.629 11.034 14 26.888.442 17.048a1.09 1.09 0 0 1-.39-1.203l1.578-4.811zm7.217 0h10.309l-5.154 15.854zM5.753 1.475l3.093 9.559H1.63l3.093-9.559a.548.548 0 0 1 1.031 0zm20.618 9.559 1.578 4.811c.141.437-.016.922-.39 1.203l-13.558 9.84 12.371-15.854zm0 0h-7.216l3.093-9.559a.548.548 0 0 1 1.031 0z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_heart" xmlns="http://www.w3.org/2000/svg"><path d="M16 29.714a1.11 1.11 0 0 1-.786-.321L4.072 18.643c-.143-.125-4.071-3.714-4.071-8 0-5.232 3.196-8.357 8.535-8.357 3.125 0 6.053 2.464 7.464 3.857 1.411-1.393 4.339-3.857 7.464-3.857 5.339 0 8.535 3.125 8.535 8.357 0 4.286-3.928 7.875-4.089 8.035L16.785 29.392c-.214.214-.5.321-.786.321z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_info_outline" xmlns="http://www.w3.org/2000/svg"><path d="M12.62 9.793V6.967h2.761v2.826H12.62zM14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm-1.38 21.033V12.62h2.761v8.413H12.62z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_keyboard_arrow_down" xmlns="http://www.w3.org/2000/svg"><path d="M3.281 5.36 14 16.079 24.719 5.36 28 8.641l-14 14-14-14z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_keyboard_arrow_left" xmlns="http://www.w3.org/2000/svg"><path d="M25.875 28.25 22.125 32 6.126 16.001 22.125.002l3.75 3.75-12.25 12.25z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_keyboard_arrow_right" xmlns="http://www.w3.org/2000/svg"><path d="M6.125 28.25 18.375 16 6.125 3.75 9.875 0l15.999 15.999L9.875 31.998z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_keyboard_arrow_up" xmlns="http://www.w3.org/2000/svg"><path d="M24.719 22.64 14 11.921 3.281 22.64 0 19.359l14-14 14 14z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_link" xmlns="http://www.w3.org/2000/svg"><path d="M24.037 7.963q3.305 0 5.634 2.366T32 16t-2.329 5.671-5.634 2.366h-6.46v-3.08h6.46q2.028 0 3.493-1.465t1.465-3.493-1.465-3.493-3.493-1.465h-6.46v-3.08h6.46zM9.615 17.578v-3.155h12.77v3.155H9.615zM3.005 16q0 2.028 1.465 3.493t3.493 1.465h6.46v3.08h-6.46q-3.305 0-5.634-2.366T0 16.001t2.329-5.671 5.634-2.366h6.46v3.08h-6.46q-2.028 0-3.493 1.465t-1.465 3.493z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_mastodon" xmlns="http://www.w3.org/2000/svg"><path d="M30.924 10.506c0-6.941-4.548-8.976-4.548-8.976C24.083.477 20.144.034 16.054.001h-.101C11.862.034 7.926.477 5.633 1.53c0 0-4.548 2.035-4.548 8.976 0 1.589-.031 3.491.02 5.505.165 6.79 1.245 13.479 7.522 15.14 2.893.765 5.379.927 7.38.816 3.629-.2 5.667-1.296 5.667-1.296l-.12-2.633s-2.593.817-5.505.719c-2.887-.099-5.932-.311-6.399-3.855a7.069 7.069 0 0 1-.064-.967v-.028.001s2.833.693 6.423.857c2.195.1 4.253-.129 6.344-.377 4.009-.479 7.5-2.949 7.939-5.207.689-3.553.633-8.676.633-8.676zm-5.366 8.945h-3.329v-8.159c0-1.72-.724-2.592-2.171-2.592-1.6 0-2.403 1.035-2.403 3.083v4.465h-3.311v-4.467c0-2.048-.803-3.083-2.403-3.083-1.447 0-2.171.873-2.171 2.592v8.159H6.441v-8.404c0-1.719.437-3.084 1.316-4.093.907-1.011 2.092-1.528 3.565-1.528 1.704 0 2.995.655 3.848 1.965l.828 1.391.829-1.391c.853-1.311 2.144-1.965 3.848-1.965 1.472 0 2.659.517 3.565 1.528.877 1.009 1.315 2.375 1.315 4.093z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_matrix" xmlns="http://www.w3.org/2000/svg"><path d="M.843.734v30.532H3.04v.733H0V0h3.04v.733zm9.391 9.68v1.543h.044a4.417 4.417 0 0 1 1.489-1.365c.577-.327 1.248-.487 2-.487.72 0 1.377.143 1.975.419.597.277 1.047.776 1.36 1.477.339-.499.8-.941 1.379-1.323.579-.383 1.267-.573 2.061-.573.604 0 1.163.075 1.68.223a3.34 3.34 0 0 1 1.324.707c.368.327.652.745.861 1.268.203.523.307 1.151.307 1.889v7.637h-3.132v-6.468c0-.381-.013-.745-.043-1.083a2.315 2.315 0 0 0-.246-.893l.006.013a1.484 1.484 0 0 0-.577-.593l-.007-.004c-.259-.147-.609-.221-1.047-.221-.443 0-.8.085-1.071.252-.267.166-.483.39-.635.656l-.005.009a2.558 2.558 0 0 0-.307.915l-.002.013a7.156 7.156 0 0 0-.08 1.044v6.359h-3.133v-6.4c0-.339-.005-.671-.024-1.003a2.772 2.772 0 0 0-.197-.936l.007.019a1.41 1.41 0 0 0-.548-.667l-.006-.003c-.259-.167-.635-.253-1.139-.253-.148 0-.345.032-.585.099-.24.068-.48.191-.707.376-.228.184-.425.449-.585.793-.16.345-.24.8-.24 1.36v6.621H7.279v-11.42zm20.923 20.852V.734H28.96V.001H32V32h-3.04v-.733z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_menu" xmlns="http://www.w3.org/2000/svg"><path d="M.001 5.334h31.998v3.583H.001V5.334zm0 12.416v-3.5h31.998v3.5H.001zm0 8.916v-3.583h31.998v3.583H.001z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_notifications" xmlns="http://www.w3.org/2000/svg"><path d="m25.846 22.154 3.308 3.308v1.615H2.847v-1.615l3.308-3.308V14q0-3.846 1.961-6.692t5.423-3.692V2.462q0-1 .692-1.731T16 0t1.769.731.692 1.731v1.154q3.461.846 5.423 3.692T25.846 14v8.154zM16 32q-1.385 0-2.346-.923t-.962-2.308h6.615q0 1.308-1 2.269T15.999 32z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_person" xmlns="http://www.w3.org/2000/svg"><path d="M16 20.023q5.052 0 10.526 2.199t5.473 5.754v4.023H0v-4.023q0-3.555 5.473-5.754t10.526-2.199zM16 16q-3.275 0-5.614-2.339T8.047 8.047t2.339-5.661T16 0t5.614 2.386 2.339 5.661-2.339 5.614T16 16z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_pin" xmlns="http://www.w3.org/2000/svg"><path d="M17.6 19.2h9.6v-1.6L22.4 16V3.2l4.8-1.6V0H4.8v1.6l4.8 1.6V16l-4.8 1.6v1.6h9.6v11.2L16 32l1.6-1.6V19.2z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_rss_feed" xmlns="http://www.w3.org/2000/svg"><path d="M-.481 12.048q8.482 0 14.457 5.976t5.976 14.457h-5.879q0-5.976-4.289-10.264T-.48 17.928v-5.879zm0-11.565q13.204 0 22.601 9.397t9.397 22.601h-5.783q0-10.891-7.662-18.553T-.481 6.266V.483zm0 27.468q0-1.831 1.301-3.132t3.229-1.301 3.181 1.253 1.253 3.181-1.301 3.229-3.132 1.301q-1.928 0-3.229-1.301T-.48 27.952z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_search" xmlns="http://www.w3.org/2000/svg"><path d="M11.925 20.161q3.432 0 5.834-2.402t2.402-5.834-2.402-5.834-5.834-2.402-5.834 2.402-2.402 5.834 2.402 5.834 5.834 2.402zm10.981 0L32 29.255 29.255 32l-9.094-9.094v-1.458l-.515-.515q-3.26 2.831-7.721 2.831-4.976 0-8.45-3.432T.001 11.925t3.474-8.45 8.45-3.474 8.407 3.474 3.432 8.45q0 1.802-.858 4.075t-1.973 3.646l.515.515h1.458z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_security" xmlns="http://www.w3.org/2000/svg"><path d="m16 0 13.072 5.855v8.715q0 6.059-3.745 11.063T16 31.999q-5.583-1.362-9.327-6.366T2.928 14.57V5.855zm0 16v13.004q4.017-1.294 6.808-4.868T26.144 16H16zm0 0V3.2L5.856 7.693v8.306H16z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_star" xmlns="http://www.w3.org/2000/svg"><path d="M14 22.052 5.324 27.31l2.3-9.859L0 10.813l10.056-.854L14 .692l3.944 9.267L28 10.813l-7.624 6.638 2.3 9.859z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_tag" xmlns="http://www.w3.org/2000/svg"><path d="M17.52 17.52v-7.041h-7.041v7.041h7.041zM28 10.479h-7.041v7.041H28v3.439h-7.041V28H17.52v-7.041h-7.041V28H7.04v-7.041H-.001V17.52H7.04v-7.041H-.001V7.04H7.04V-.001h3.439V7.04h7.041V-.001h3.439V7.04H28v3.439z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_timer" xmlns="http://www.w3.org/2000/svg"><path d="M16 29q4.428 0 7.536-3.143t3.107-7.571-3.107-7.536T16 7.643 8.464 10.75t-3.107 7.536 3.107 7.571T16 29zM26.714 9.786q1.214 1.571 2.107 4.036t.893 4.464q0 5.643-4 9.678T16 32t-9.714-4.036-4-9.678 4-9.678T16 4.572q1.929 0 4.464.929t4.107 2.143l2.143-2.214q1.143.929 2.143 2.143zM14.5 19.857v-9.143h3v9.143h-3zM20.571.001v3.071h-9.143V.001h9.143z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_tree" xmlns="http://www.w3.org/2000/svg"><path d="M32 14.423H20.808V9.616h-3.23v12.77h3.23v-4.807H32v12.845H20.808v-4.807h-6.385v-16h-3.23v4.807H.001V1.579h11.192v4.807h9.615V1.579H32v12.845z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_xmpp" xmlns="http://www.w3.org/2000/svg"><path d="M31.995 4.237c-.449.175-1.12.433-1.936.745-1.544.591-2.328.891-2.924 1.093-.613.208-1.287.409-2.635.813-.911.272-1.672.495-2.212.651-.031.875 0 2.177-.292 3.635a21.837 21.837 0 0 1-2.016 5.765c-1.496 2.944-3.236 4.817-3.88 5.476-.056-.059-.112-.117-.168-.179-.707-.763-2.403-2.703-3.815-5.683-1.053-2.223-1.484-4.044-1.605-4.584-.356-1.589-.427-2.955-.427-4.117 0-.075-.036-.129-.101-.149-.721-.223-1.765-.519-2.887-.853-1.271-.379-2.193-.744-3.408-1.2-.493-.185-1.409-.547-2.217-.859C.723 4.499.113 4.236.041 4.236c-.005 0-.015 0-.023.012a.131.131 0 0 0-.019.076c.009.593.08 1.361.256 2.365.615 3.503 2.688 7.061 4.36 9.244 0 0 3.717 5.035 9.128 8.144l.303.176c-.009.008-.02.015-.028.021-1.717 1.316-3.201 1.977-3.579 2.14a15.71 15.71 0 0 1-2.219.772v.407a25.31 25.31 0 0 0 2.72-.487 26.72 26.72 0 0 0 5.075-1.792c.136.067.276.136.42.204 1.527.725 3.571 1.627 6.073 2.048.613.103 1.136.165 1.507.195a.109.109 0 0 0 .115-.091.55.55 0 0 0 .004-.217.107.107 0 0 0-.063-.073c-.505-.209-1.201-.4-1.983-.719-.935-.381-2.241-1.067-3.648-2.128a13.528 13.528 0 0 1-.367-.287c4.64-2.656 7.989-6.588 7.989-6.588 1.735-2.036 4.441-5.623 5.431-9.795.349-1.473.539-2.741.5-3.628z"/></svg></defs></svg>




    <div
      class="wrapper "
    >
      <header class="gblog-header">
  <div class="container flex flex-wrap">
    <div class="gblog-header__col-1 flex justify-start hidden-mobile"></div>
    <div class="gblog-header__col-2 flex align-center justify-center ">
      <a class="gblog-header__link" rel="me" href="https://example.org/">
        <span class="gblog-brand flex align-center justify-center">
          <img
            class="gblog-brand__img"
            src="/brand.svg"
            alt=""
          />
          <span class="gblog-brand__title">Wild Bill Blog</span>
        </span>
        
      </a>
    </div>
    <div class="gblog-header__col-3 flex justify-end">
      <span id="gblog-color-theme">
        <svg class="gblog-icon gblog_brightness_dark">
          <title></title>
          <use xlink:href="#gblog_brightness_dark"></use>
        </svg>
        <svg class="gblog-icon gblog_brightness_light">
          <title></title>
          <use xlink:href="#gblog_brightness_light"></use>
        </svg>
        <svg class="gblog-icon gblog_brightness_auto">
          <title></title>
          <use xlink:href="#gblog_brightness_auto"></use>
        </svg>
      </span>
    </div>
  </div>
</header>
<nav class="gblog-nav">
  <input type="checkbox" id="menu-control" class="hidden" />
  <div class="gblog-nav__control">
    <label for="menu-control" class="flex align-center justify-center">
      <svg class="gblog-icon gblog_menu"><use xlink:href="#gblog_menu"></use></svg>
      <svg class="gblog-icon gblog_clear"><use xlink:href="#gblog_clear"></use></svg>
      <span>Navigation</span>
    </label>
  </div>
  <ul class="gblog-nav__list container flex flex-wrap justify-center menu-content">
    
    
      
    
    
  </ul>
</nav>



      <main class="gblog-page container">
        
  <article class="gblog-post">
    <header class="gblog-post__header">
      
      


      <h1 class="gblog-post__title">开发一个本地大模型应用</h1>

      
        <div class="flex flex-wrap align-center gblog-post__meta gblog-post__meta--head">
          <span class="flex align-center no-wrap gblog-post__meta--update">
  <svg class="gblog-icon gblog_date"><use xlink:href="#gblog_date"></use></svg>
  <span class="gblog-post__tag">
    <time datetime="2024-10-09T14:45:23&#43;08:00">
      
      Oct 9, 2024
    </time>
  </span>
</span>

<span class="flex align-center no-wrap gblog-post__meta--readtime">
  <svg class="gblog-icon gblog_timer"><use xlink:href="#gblog_timer"></use></svg>
  <span class="gblog-post__tag">3 min read</span>
</span>













        </div>
      
    </header>
    <section class="gblog-markdown">
      <p>[TOC]</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="一大模型简介"
    >
        一、大模型简介
    </h2>
    <a data-clipboard-text="https://example.org/post/first_big_model/#一大模型简介" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 一、大模型简介" href="#%e4%b8%80%e5%a4%a7%e6%a8%a1%e5%9e%8b%e7%ae%80%e4%bb%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="11-什么是大模型"
    >
        1.1 什么是大模型
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#11-什么是大模型" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 1.1 什么是大模型" href="#11-%e4%bb%80%e4%b9%88%e6%98%af%e5%a4%a7%e6%a8%a1%e5%9e%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型。
LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。
大模型实际上是个语言模型，用来处理复杂的语言任务，如文本生成、语言翻译、问题回答等。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="12-为什么叫大模型"
    >
        1.2 为什么叫大模型
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#12-为什么叫大模型" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 1.2 为什么叫大模型" href="#12-%e4%b8%ba%e4%bb%80%e4%b9%88%e5%8f%ab%e5%a4%a7%e6%a8%a1%e5%9e%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>大模型也是属于机器学习的一种，是深度学习的思想融入语言模型中的强大神经网络模型。
模型通俗的理解，就是数学模型，用公式来说就是y=fn(x1,x2)
大模型主要体现在这个大字。大的概念是一个参数多，能达到上亿个参数。对应公式中可能存在上亿个参数。另一个是数据量大，用于训练的数据可以达到PB级别。再者就是计算资源密集，训练和推理需要大量的计算资源。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="二检索增强生成rag简介"
    >
        二、检索增强生成RAG简介
    </h2>
    <a data-clipboard-text="https://example.org/post/first_big_model/#二检索增强生成rag简介" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 二、检索增强生成RAG简介" href="#%e4%ba%8c%e6%a3%80%e7%b4%a2%e5%a2%9e%e5%bc%ba%e7%94%9f%e6%88%90rag%e7%ae%80%e4%bb%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="21-什么是rag"
    >
        2.1 什么是RAG
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#21-什么是rag" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 2.1 什么是RAG" href="#21-%e4%bb%80%e4%b9%88%e6%98%afrag">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>大模型不是万能的，在某些情况下，无法提供准确的答案。为了提高模型的性能和输出质量，产生了一种新的模型架构方式：检索增强生成（RAG, Retrieval-Augmented Generation）</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="211-llm面临的问题"
    >
        2.1.1 LLM面临的问题
    </h4>
    <a data-clipboard-text="https://example.org/post/first_big_model/#211-llm面临的问题" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 2.1.1 LLM面临的问题" href="#211-llm%e9%9d%a2%e4%b8%b4%e7%9a%84%e9%97%ae%e9%a2%98">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<ul>
<li>知识更新滞后：LLM训练时用的静态数据集训练，比如说，训练的基础模型是24年前爬取的各类数据。那么原则上说，模型不可能知道2024年之后的信息内容。你问2024年发生了哪些大事件，模型肯定给不出对应的答案。所以通过RAG实时检索当前搜索引擎最新数据，保证内容的时效性，确保信息的持续更新和准确性。</li>
<li>专业领域知识欠缺：LLM在处理特定领域的专业知识时，效果不太理想。因为训练LLM的数据集都是公开的互联网数据以及各类公开发行的书籍之类的资源。但是如果是某个企业的私有业务功能及数据，LLM是不认识的，RAG可以检索特定领域的相关文档，为模型提供丰富上下文信息，从而提升专业领域内的问题回答质量和深度。</li>
</ul>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="22-rag工作流程"
    >
        2.2 RAG工作流程
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#22-rag工作流程" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 2.2 RAG工作流程" href="#22-rag%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>数据处理：</p>
<ul>
<li>对原始数据进行清洗和处理</li>
<li>将处理后的数据转化为检索模型可以使用</li>
<li>将处理后的数据存储在特定数据库中
信息检索：检索器会根据用户的问题，从一个预先构建的知识库中找到最相关的文档或段落。
信息生成：生成器利用检索器提供的相关信息，再结合用户的输入，生成回答。
输出：返回基于外部知识增强后的生成结果给用户。</li>
</ul>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="23-提高大模型准确性的其他方式"
    >
        2.3 提高大模型准确性的其他方式
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#23-提高大模型准确性的其他方式" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 2.3 提高大模型准确性的其他方式" href="#23-%e6%8f%90%e9%ab%98%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%87%86%e7%a1%ae%e6%80%a7%e7%9a%84%e5%85%b6%e4%bb%96%e6%96%b9%e5%bc%8f">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>目前在提升大语言模型效果中，RAG和微调(Finetune)是两种主流的方法。
微调：在特定数据集上进一步训练大语言模型，来提升模型在特定任务上的表现。
RAG和微调的对比：
暂时无法在飞书文档外展示此内容
微调这块比较吃优质的数据集，并且还伴随大量的计算资源。成本比较高。优质的数据集，目前大部分是人工标注，都是人力堆出来的。而且一般个人开发者或者小公司，很少有资源能够去做这个微调。更关键的是，如果微调训练后的模型裂化了，那么这个模型就没用了，无法恢复到之前的某个状态。
LangChain简介
LangChain 是一个用于构建基于大语言模型（LLM）应用的框架，它使得开发者能够更容易地将语言模型与外部工具、数据源或环境集成起来，从而实现更复杂的应用。LangChain 的设计目标是帮助开发者搭建能够进行复杂推理、增强记忆、检索外部信息等功能的应用。
LangChain 的核心功能是将大语言模型（如 GPT、BERT 等）与多个外部系统结合起来，比如数据库、API、文件系统等，使得模型不仅能基于自身训练的知识进行推理，还能实时获取外部信息进行更准确或实时的回答。
<a
  class="gblog-markdown__link"
  href="LangChain"
>langchain官网</a></p>
<p>LangChain 的主要组件：</p>
<ol>
<li>语言模型（LLM）接口：LangChain 支持与多种大语言模型交互，比如 OpenAI 的 GPT 系列、HuggingFace 的模型、Cohere 等。开发者可以利用这些模型生成文本、回答问题、进行对话等。</li>
<li>链（Chain）：链是 LangChain 中的一个核心概念，它允许将多个步骤或模型串联起来。例如，你可以先从数据库中检索信息，然后让大语言模型对这些信息进行总结，最后输出给用户。每个步骤都可以是一个独立的处理逻辑。</li>
<li>工具（Tools）：LangChain 可以集成外部工具或 API，让大语言模型调用这些工具来扩展其功能。例如，模型可以通过查询数据库、访问网络 API 或者从文档库中检索信息来增强回答的质量。</li>
<li>记忆（Memory）：LangChain 提供了一种“记忆”机制，使得语言模型可以在会话过程中记住之前的上下文。这对于实现对话机器人或长期交互系统非常有用，它可以让模型基于之前的对话内容生成连续、相关的回应。</li>
<li>检索增强生成（RAG）：LangChain 也支持通过 RAG 技术来增强生成能力，结合外部的文档库或数据库，使模型生成更加准确和基于事实的内容。</li>
<li>代理（Agents）：LangChain 支持创建智能代理系统，允许语言模型根据上下文和规则，动态选择要执行的动作。例如，一个代理系统可以根据用户的输入来决定是否需要从外部系统检索信息、执行计算，或与用户对话
一句话总结，这就是个大模型应用的开发框架，里面封装了各个组件，能够开箱即用，简化开发过程。</li>
</ol>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="三什么是大模型开发"
    >
        三、什么是大模型开发
    </h2>
    <a data-clipboard-text="https://example.org/post/first_big_model/#三什么是大模型开发" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 三、什么是大模型开发" href="#%e4%b8%89%e4%bb%80%e4%b9%88%e6%98%af%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%bc%80%e5%8f%91">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>以大语言模型为功能核心、通过大语言模型的强大理解能力和生成能力、结合特殊的数据或业务逻辑来提供独特功能的应用称为大模型开发。
开发大模型相关应用，其技术核心点虽然在大语言模型上，但一般通过调用 API 或开源模型来实现核心的理解与生成，通过 Prompt Enginnering 来实现大语言模型的控制，因此，虽然大模型是深度学习领域的集大成之作，大模型开发却更多是一个工程问题。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="31-大模型开发与ai应用开发的差异"
    >
        3.1 大模型开发与AI应用开发的差异
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#31-大模型开发与ai应用开发的差异" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 3.1 大模型开发与AI应用开发的差异" href="#31-%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%bc%80%e5%8f%91%e4%b8%8eai%e5%ba%94%e7%94%a8%e5%bc%80%e5%8f%91%e7%9a%84%e5%b7%ae%e5%bc%82">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>以调用、发挥大模型为核心的大模型开发与传统的 AI 开发在整体思路上有着较大的不同。大语言模型的两个核心能力：指令遵循与文本生成提供了复杂业务逻辑的简单平替方案。</p>
<ul>
<li>传统的 AI 开发：首先需要将非常复杂的业务逻辑依次拆解，对于每一个子业务构造训练数据与验证数据，对于每一个子业务训练优化模型，最后形成完整的模型链路来解决整个业务逻辑。</li>
<li>大模型开发：用 Prompt Engineering 来替代子模型的训练调优，通过 Prompt 链路组合来实现业务逻辑，用一个通用大模型 + 若干业务 Prompt 来解决任务，从而将传统的模型训练调优转变成了更简单、轻松、低成本的 Prompt 设计调优。
同时，在评估思路上，大模型开发与传统 AI 开发也有质的差异。</li>
<li>传统 AI 开发：需要首先构造训练集、测试集、验证集，通过在训练集上训练模型、在测试集上调优模型、在验证集上最终验证模型效果来实现性能的评估。</li>
<li>大模型开发：流程更为灵活和敏捷。从实际业务需求出发构造小批量验证集，设计合理 Prompt 来满足验证集效果。然后，将不断从业务逻辑中收集当下 Prompt 的 Bad Case，并将 Bad Case 加入到验证集中，针对性优化 Prompt，最后实现较好的泛化效果。</li>
</ul>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="32-大模型开发基础要素"
    >
        3.2 大模型开发基础要素
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#32-大模型开发基础要素" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 3.2 大模型开发基础要素" href="#32-%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%bc%80%e5%8f%91%e5%9f%ba%e7%a1%80%e8%a6%81%e7%b4%a0">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<ol>
<li>框架：LangChain
框架可以使用langchain，为了方便小白玩，langflow这个可视化编辑挺好用。</li>
<li>Embedding模型
embedding是什么，首先我们使用RAG来做增强检索，基于语言的检索不同于常规的关系数据库检索，而是向量检索，对于一段文本，用什么模型进行向量化，就是这个embedding模型需要做的。</li>
<li>数据库
同样的，构建的知识库或者本地文档库，用什么来存储，就是这个数据库需要做的。一般这个数据库是个向量数据库。</li>
<li>基础大模型
这个很容易理解，是openAI的chatgpt、还是文心一言、通义千问</li>
</ol>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="四开发一个本地大模型应用"
    >
        四、开发一个本地大模型应用
    </h2>
    <a data-clipboard-text="https://example.org/post/first_big_model/#四开发一个本地大模型应用" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 四、开发一个本地大模型应用" href="#%e5%9b%9b%e5%bc%80%e5%8f%91%e4%b8%80%e4%b8%aa%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%ba%94%e7%94%a8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>上面介绍了很多，下面来实战。先最简单做一个应用。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="41-依赖安装"
    >
        4.1 依赖安装
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#41-依赖安装" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.1 依赖安装" href="#41-%e4%be%9d%e8%b5%96%e5%ae%89%e8%a3%85">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="411-langflow安装"
    >
        4.1.1 langflow安装
    </h4>
    <a data-clipboard-text="https://example.org/post/first_big_model/#411-langflow安装" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.1.1 langflow安装" href="#411-langflow%e5%ae%89%e8%a3%85">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>langflow是一个可视化编辑器。
安装命令（要求python3.10以上）
<code>pip install langflow</code></p>
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="412-ollama下载"
    >
        4.1.2 ollama下载
    </h4>
    <a data-clipboard-text="https://example.org/post/first_big_model/#412-ollama下载" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.1.2 ollama下载" href="#412-ollama%e4%b8%8b%e8%bd%bd">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Ollama 是一种基于本地大语言模型的工具或框架，旨在让开发者能够在本地环境中运行和使用大语言模型，而无需依赖云端服务
去https://ollama.com/官网下载，安装。
有两个环境变量需要注意：
OLLAMA_MODELS：OLLAMA模型的下载路径。
OLLAMA_HOST: OLLAMA模型以服务方式运行的时候，即提供API，默认是只能被localhost访问的，设置这个为0.0.0.0，可以被网络访问。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="413-下载大模型"
    >
        4.1.3 下载大模型
    </h4>
    <a data-clipboard-text="https://example.org/post/first_big_model/#413-下载大模型" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.1.3 下载大模型" href="#413-%e4%b8%8b%e8%bd%bd%e5%a4%a7%e6%a8%a1%e5%9e%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>ollama安装完成后，命令行输入<code>ollama</code>，会有对应的命令帮助。
运行<code>ollama pull llama3:8b</code>，下载大模型。
下载完成后，运行<code>ollama run llama3:8b</code>，可以进行语言聊天。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="42-开始开发"
    >
        4.2 开始开发
    </h2>
    <a data-clipboard-text="https://example.org/post/first_big_model/#42-开始开发" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.2 开始开发" href="#42-%e5%bc%80%e5%a7%8b%e5%bc%80%e5%8f%91">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="421-运行langflow"
    >
        4.2.1 运行langflow
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#421-运行langflow" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.2.1 运行langflow" href="#421-%e8%bf%90%e8%a1%8clangflow">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>在命令行中运行langflow，<code>python -m langflow run</code>
然后访问<code>http://127.0.0.1:7860</code>，会弹出一个可视化编辑界面。
<img
  src="/img/ai/langflow_overview.png"
  alt=""
  
/></p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="422-运行大模型"
    >
        4.2.2 运行大模型
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#422-运行大模型" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.2.2 运行大模型" href="#422-%e8%bf%90%e8%a1%8c%e5%a4%a7%e6%a8%a1%e5%9e%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><code>ollama run llama3:8b</code>
访问<code>http://localhost:11434</code>，会有输出Ollama is running</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="423-选择一个模板进行开发"
    >
        4.2.3 选择一个模板进行开发
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#423-选择一个模板进行开发" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.2.3 选择一个模板进行开发" href="#423-%e9%80%89%e6%8b%a9%e4%b8%80%e4%b8%aa%e6%a8%a1%e6%9d%bf%e8%bf%9b%e8%a1%8c%e5%bc%80%e5%8f%91">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>点击new project，选择一个模板
<img
  src="/img/ai/template.png"
  alt="alt text"
  
/>
我选择Vector Store RAG，跟我目前的需求比较匹配。
<img
  src="/img/ai/flow_demo.png"
  alt=""
  
/>
具体修改点：</p>
<ol>
<li>将模型换成ollama，找到左边组件中model，替换成本地我们下载的模型。如果用其他模型，都需要api_key，大部分都是要收钱。</li>
<li>向量数据库使用ChromaDB，chromadb是本地存储。</li>
<li>embedding选择ollama对应的值</li>
</ol>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="424-构建"
    >
        4.2.4 构建
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#424-构建" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.2.4 构建" href="#424-%e6%9e%84%e5%bb%ba">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>从图中，可以看到2条路径，一条是构建向量数据库，一条是运行应用。
我们先构建向量数据库数据，点击Chroma DB的运行按钮，就能构建。
我选择了一个零一万物福利手册pdf作为文件录入数据库。点击运行
<img
  src="/img/ai/build_flow.png"
  alt=""
  
/>
然后点击Retriever，可以看到建模的数据。
<img
  src="/img/ai/retriver.png"
  alt=""
  
/></p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="425-对比效果"
    >
        4.2.5 对比效果
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#425-对比效果" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.2.5 对比效果" href="#425-%e5%af%b9%e6%af%94%e6%95%88%e6%9e%9c">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>点击playground，可以在线测试效果。
<img
  src="/img/ai/test_flow.png"
  alt=""
  
/></p>
<p>我们看下不用RAG的大模型输出。
输入是零一万物有哪些福利？</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>零一万物 (Zhēng Yī Wàn Wù) is a Chinese term that literally means 
</span></span><span style="display:flex;"><span>&#34;Zero to Ten Thousand Things&#34; or &#34;All Under Heaven&#34;. It refers to the vast 
</span></span><span style="display:flex;"><span>and diverse universe, encompassing all existence, phenomena, and beings. 
</span></span><span style="display:flex;"><span>In this context, &#34;福利&#34; (fèi lì) means benefits or advantages.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>So, when we talk about the welfare of zero to ten thousand things, it&#39;s a 
</span></span><span style="display:flex;"><span>philosophical and cosmological concept that considers the well-being and 
</span></span><span style="display:flex;"><span>flourishing of all existence within the vast expanse of the universe. Here 
</span></span><span style="display:flex;"><span>are some potential benefits:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>1. **Interconnectedness**: Recognizing the intricate web of relationships 
</span></span><span style="display:flex;"><span>between all phenomena, fostering harmony and cooperation.
</span></span><span style="display:flex;"><span>2. **Dynamic Balance**: Understanding the ever-changing nature of the 
</span></span><span style="display:flex;"><span>universe, allowing for adaptation and resilience in the face of 
</span></span><span style="display:flex;"><span>uncertainty.
</span></span><span style="display:flex;"><span>3. **Compassion and Empathy**: Cultivating a sense of shared humanity (and 
</span></span><span style="display:flex;"><span>non-humanity) across the vast expanse of existence, promoting kindness and 
</span></span><span style="display:flex;"><span>understanding.
</span></span><span style="display:flex;"><span>4. **Cyclical Renewal**: Embracing the cycles of birth, growth, decay, and 
</span></span><span style="display:flex;"><span>rebirth, acknowledging the eternal nature of change and transformation.
</span></span><span style="display:flex;"><span>5. **Holistic Awareness**: Integrating the wisdom of various disciplines 
</span></span><span style="display:flex;"><span>(e.g., science, philosophy, spirituality) to grasp the complexity and 
</span></span><span style="display:flex;"><span>beauty of existence.
</span></span><span style="display:flex;"><span>6. **Non-dualism**: Recognizing that distinctions between subject-object, 
</span></span><span style="display:flex;"><span>self-other, and being-non-being are ultimately illusory, promoting a 
</span></span><span style="display:flex;"><span>deeper sense of unity and wholeness.
</span></span><span style="display:flex;"><span>7. **Evolving Intelligence**: Honoring the evolutionary nature of 
</span></span><span style="display:flex;"><span>intelligence, acknowledging the potential for growth and development 
</span></span><span style="display:flex;"><span>within all beings.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>These benefits can guide our understanding of the universe, inspiring us 
</span></span><span style="display:flex;"><span>to live in harmony with the natural world, appreciate the intricate web of 
</span></span><span style="display:flex;"><span>relationships, and cultivate a sense of compassion and connection with all 
</span></span><span style="display:flex;"><span>existence. 🌊💖
</span></span></code></pre></div><p>让大模型用中文回答一遍，结果是这样的：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>零一万物（Zhēng Yī Wàn Wù）的福利指的是宇宙中所有事物的福利，这是一个哲
</span></span><span style="display:flex;"><span>学和宇宙学概念，考虑宇宙中所有存在的福祉和 процветание。以下是可
</span></span><span style="display:flex;"><span>能的福利：
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>1. **互连关系**：认清宇宙中所有事物之间的 intricate 网络关系，培养和谐和合作
</span></span><span style="display:flex;"><span>。
</span></span><span style="display:flex;"><span>2. **动态平衡**：理解宇宙的变化性质，使其在不确定的情况下适应和恢复。
</span></span><span style="display:flex;"><span>3. **同情心和同体共感**：培养对所有存在的同情心和同体共感，促进慷慨和理解。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>4. **循环更新**：承认宇宙中的生、长、衰、更新的循环，表彰变化和更新的永恒性
</span></span><span style="display:flex;"><span>质。
</span></span><span style="display:flex;"><span>5. **holistic Awareness**：整合各种学科（例如科学、哲学、精神）来理解宇宙的
</span></span><span style="display:flex;"><span>复杂和美丽。
</span></span><span style="display:flex;"><span>6. **非二元论**：认清主题-客体、自我他人的区别和有-无之间的 illusion，促进更
</span></span><span style="display:flex;"><span>深入的 unity 和整体感。
</span></span><span style="display:flex;"><span>7. **演化智慧**：表彰智能的演化性质，使其在所有存在中增长和发展。
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>这些福利可以指导我们对宇宙的理解，鼓励我们与自然世界和谐，欣赏事物之间的 
</span></span><span style="display:flex;"><span>intricate 网络关系，并培养同情心和连接所有存在。 🌊💖
</span></span></code></pre></div><p>然后我们用langflow的playground，运行我们的查询，得到的结果：</p>
<pre tabindex="0"><code>根据提供的文本内容，零一万物（可能指的是某种保险或医疗服务）的福利包括：
原发性血小板增多症
自身免疫性溶血性贫血
骨髓异常增生综合症
慢性胃炎
克罗恩病
重症肌无力
慢性乙型肝炎、慢性丙型肝炎、慢性丁型肝炎
肝硬化
慢性肾炎、慢性肾功能不全（非透析治疗）
系统性红斑狼疮
慢性再生障碍性贫血
颅内良性肿瘤
骨髓纤维化
这些福利可能与某种保险或医疗服务有关，具体内容需要根据上下文进行理解。
当然结果不算很正确，但是至少靠近了。
</code></pre><p>说明RAG的作用还是有的，剩下就是更好的构建向量数据库，挑选合适的embedding模型，并且搭配合理的Prompt。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="425-发布api"
    >
        4.2.5 发布api
    </h3>
    <a data-clipboard-text="https://example.org/post/first_big_model/#425-发布api" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 4.2.5 发布api" href="#425-%e5%8f%91%e5%b8%83api">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>langflow支持api调用，点击api可以看到对应的api调用方式模板。
<img
  src="/img/ai/flow_api.png"
  alt=""
  
/>
当调试好应用后，就可以通过这个api发布出去，可以通过http请求调用。</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="五参考资料"
    >
        五、参考资料
    </h2>
    <a data-clipboard-text="https://example.org/post/first_big_model/#五参考资料" class="gblog-post__anchor clip flex align-center" aria-label="Anchor 五、参考资料" href="#%e4%ba%94%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<ol>
<li><a
  class="gblog-markdown__link"
  href="https://datawhalechina.github.io/llm-universe/#/./C1/1.%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20LLM%20%E7%90%86%E8%AE%BA%E7%AE%80%E4%BB%8B"
>动手学大模型应用开发</a></li>
<li><a
  class="gblog-markdown__link"
  href="https://www.langchain.com/"
>langchain</a></li>
<li><a
  class="gblog-markdown__link"
  href="https://www.langflow.org/"
>langflow</a></li>
<li><a
  class="gblog-markdown__link"
  href="https://gitcode.csdn.net/66c6d3551016441633659a8f.html"
>langchain+ollama构建本地大模型应用</a></li>
</ol>

    </section>
  </article>

      </main>

      <footer class="gblog-footer">
  <nav class="container flex">
    <div>
      <section class="flex flex-wrap align-center">
        
        
        
        
      </section>
      <section class="flex flex-wrap align-center">
        <span class="gblog-footer__item">
          Built with <a href="https://gohugo.io/" class="gblog-footer__link">Hugo</a> and
          <svg class="gblog-icon gblog_heart"><use xlink:href="#gblog_heart"></use></svg>
        </span>
      </section>
      
      
    </div>
    
      <div class="flex flex-25 justify-end">
        <span class="gblog-footer__item text-right">
          <a class="gblog-footer__link fake-link" href="#" aria-label="Back to top">
            <svg class="gblog-icon gblog_keyboard_arrow_up">
              <use xlink:href="#gblog_keyboard_arrow_up"></use>
            </svg>
            <span class="hidden-mobile">Back to top</span>
          </a>
        </span>
      </div>
    
  </nav>
</footer>

    </div>
  </body>
</html>
